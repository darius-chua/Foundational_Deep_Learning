{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jErGO_I1A5PX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfd271ac-68f6-4c90-d903-9aa74386d58b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import PIL\n",
        "import glob \n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "\n",
        "import cv2\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive = drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bs7YWfcEDipU"
      },
      "outputs": [],
      "source": [
        "# Import data\n",
        "train_images = r'/content/drive/MyDrive/DSBA/Hurricane_Harvey/train'\n",
        "train_masks = r'/content/drive/MyDrive/DSBA/Hurricane_Harvey/Masks'\n",
        "test_images = r'/content/drive/MyDrive/DSBA/Hurricane_Harvey/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEjZZR9kYxaV"
      },
      "outputs": [],
      "source": [
        "train_files = os.listdir(train_images)\n",
        "train_files = [x.split('.')[0] for x in train_files if x[0].isnumeric()]\n",
        "train_files = np.array(train_files)\n",
        "#train_files = np.random.choice(train_files, size=1000, replace=False)\n",
        "# Split data\n",
        "X_train, X_val = train_test_split(train_files, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train),len(X_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPhLIXTDl20l",
        "outputId": "b98e1721-59da-4046-ffd4-88746d59c592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "239 60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNZooVOa0QPx"
      },
      "outputs": [],
      "source": [
        "dim = 2048\n",
        "#img_list = []\n",
        "\n",
        "#for im_file in train_files:\n",
        "#    img = cv2.imread(f'{train_images}/{im_file}.tif')\n",
        "#    img = cv2.resize(img,(dim,dim))\n",
        "#    img = img / 255.0\n",
        "\n",
        "#    img_list.append(img)\n",
        "\n",
        "#img_list = np.stack(img_list)\n",
        "#print(img_list.shape)\n",
        "\n",
        "#means = np.mean(img_list,axis=(0,1,2))\n",
        "#stdevs = np.std(img_list,axis=(0,1,2))\n",
        "\n",
        "#print(means,stdevs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eU7WCmT9CZbm"
      },
      "outputs": [],
      "source": [
        "class UAVDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, img_path, mask_path, X, mean, std, aug=None):\n",
        "        self.img_path = img_path\n",
        "        self.mask_path = mask_path\n",
        "        self.X = X\n",
        "        self.aug = aug\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img = cv2.imread(f'{self.img_path}/{self.X[idx]}.tif')\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  \n",
        "        mask = cv2.imread(f'{self.mask_path}/{self.X[idx]}.png', cv2.IMREAD_GRAYSCALE)\n",
        "        if self.aug is not None:\n",
        "            aug = self.aug(image=img, mask=mask)\n",
        "            img = Image.fromarray(aug['image'])\n",
        "            mask = aug['mask']\n",
        "        \n",
        "        if self.aug is None:\n",
        "            img = Image.fromarray(img)\n",
        "        \n",
        "        transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(self.mean, self.std)])\n",
        "        img = transform(img)\n",
        "\n",
        "        mask = torch.from_numpy(mask).long()\n",
        "            \n",
        "        return img, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtRAeKjnxIZj"
      },
      "outputs": [],
      "source": [
        "means = [0.38980951, 0.46497215, 0.43926388]\n",
        "stdevs = [0.21997646, 0.19580692, 0.21212297]\n",
        "\n",
        "transform_train = A.Compose([A.Resize(dim, dim, interpolation=cv2.INTER_NEAREST)])                              \n",
        "\n",
        "transform_val = A.Compose([A.Resize(dim, dim, interpolation=cv2.INTER_NEAREST)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bGao4T0CPYz"
      },
      "outputs": [],
      "source": [
        "#datasets\n",
        "train_set = UAVDataset(train_images, train_masks, train_files, means, stdevs, transform_train)\n",
        "val_set = UAVDataset(train_images, train_masks, X_val, means, stdevs, transform_val)\n",
        "\n",
        "#dataloader\n",
        "batch_size = 4\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, num_workers = 1, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld65tDgsA5Pg"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "BfW2IjRGA5Pi"
      },
      "outputs": [],
      "source": [
        "# Define double convolution structure\n",
        "def double_conv(in_c, out_c):\n",
        "    conv = nn.Sequential(\n",
        "        nn.Conv2d(in_c,out_c,3,1,padding='same'),\n",
        "        # Add 2 extra batch normalization layers\n",
        "        nn.BatchNorm2d(out_c),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_c,out_c,3,1,padding='same'),\n",
        "        nn.BatchNorm2d(out_c),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    return conv\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        \n",
        "        #Downsampling \n",
        "        \n",
        "        self.downlayer1 = double_conv(3, 16)\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "        \n",
        "        #Add dropout layer\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        \n",
        "        self.downlayer2 = double_conv(16, 32)\n",
        "        \n",
        "        self.downlayer3 = double_conv(32, 64)\n",
        "        \n",
        "        self.downlayer4 = double_conv(64, 128)\n",
        "        \n",
        "        self.downlayer5 = double_conv(128, 256)\n",
        "        \n",
        "        \n",
        "        #UpSampling\n",
        "        self.up_trans1 = nn.ConvTranspose2d(256,128,2,2)\n",
        "        self.up_conv1 = double_conv(256, 128)\n",
        "        \n",
        "        self.up_trans2 = nn.ConvTranspose2d(128,64,2,2)\n",
        "        self.up_conv2 = double_conv(128, 64)\n",
        "        \n",
        "        self.up_trans3 = nn.ConvTranspose2d(64,32,2,2)\n",
        "        self.up_conv3 = double_conv(64, 32)\n",
        "        \n",
        "        self.up_trans4 = nn.ConvTranspose2d(32,16,2,2)\n",
        "        self.up_conv4 = double_conv(32, 16)\n",
        "        \n",
        "        self.output = nn.Conv2d(16,27,kernel_size = 1)\n",
        "        \n",
        "        #normaliza output\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        \n",
        "        \n",
        "    def forward(self,x):\n",
        "        \n",
        "        #encoder\n",
        "        x1 = self.downlayer1(x) #\n",
        "        x2 = self.maxpool(x1)\n",
        "        x3 = self.dropout(x2)\n",
        "        \n",
        "        x4 = self.downlayer2(x3) #\n",
        "        x5 = self.maxpool(x4)\n",
        "        x6 = self.dropout(x5)\n",
        "        \n",
        "        x7 = self.downlayer3(x6) #\n",
        "        x8 = self.maxpool(x7)\n",
        "        x9 = self.dropout(x8)\n",
        " \n",
        "        x10 = self.downlayer4(x9) #\n",
        "        x11 = self.maxpool(x10)\n",
        "        x12 = self.dropout(x11)\n",
        "        \n",
        "        x13 = self.downlayer5(x12)\n",
        "        \n",
        "        \n",
        "        #decoder\n",
        "        x = self.up_trans1(x13)\n",
        "        x = self.up_conv1(torch.cat([x,x10],1))\n",
        "        \n",
        "        x = self.up_trans2(x)\n",
        "        x = self.up_conv2(torch.cat([x,x7],1))\n",
        "        \n",
        "        x = self.up_trans3(x)\n",
        "        x = self.up_conv3(torch.cat([x,x4],1))\n",
        "        \n",
        "        x = self.up_trans4(x)\n",
        "        x = self.up_conv4(torch.cat([x,x1],1))\n",
        "        \n",
        "        output = self.output(x)\n",
        "        output = self.softmax(output)\n",
        "        \n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jPUtauiDA5Pj"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "8iCIhfq6A5Pk"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "\n",
        "model = Generator()\n",
        "model.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "epochs = 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3wGF8BIA5Pl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "6a8f3303-f905-4229-e542-653eb3ae2a64"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-07ae66c48346>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m           \u001b[0;31m# Calculating gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m           \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m           \u001b[0;31m# Update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.69 GiB (GPU 0; 39.59 GiB total capacity; 27.62 GiB already allocated; 1.61 GiB free; 36.16 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "total_train_losses = []\n",
        "total_val_losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "      train_losses = []\n",
        "      val_losses = []\n",
        "\n",
        "      model.train()\n",
        "      for i, (images, labels) in enumerate(train_loader):\n",
        "          \n",
        "          images = images.to(device=device, dtype=torch.float)\n",
        "          labels = labels.to(device=device, dtype=torch.int64)\n",
        "          \n",
        "          # Clear gradients\n",
        "          optimizer.zero_grad()\n",
        "          \n",
        "          # Forward propagation\n",
        "          outputs = model(images)\n",
        "        \n",
        "          # Calculate softmax and ross entropy loss\n",
        "          loss = criterion(outputs, labels)\n",
        "          \n",
        "          # Calculating gradients\n",
        "          loss.backward()\n",
        "          \n",
        "          # Update parameters\n",
        "          optimizer.step()\n",
        "          \n",
        "          train_losses.append(loss.item())\n",
        "\n",
        "      train_loss_mean = np.mean(train_losses)\n",
        "      total_train_losses.append(train_loss_mean)\n",
        "\n",
        "      model.eval()\n",
        "      for i, (images, labels) in enumerate(val_loader):\n",
        "        \n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "       \n",
        "        target = model(images)\n",
        "\n",
        "        loss = criterion(target, labels)\n",
        "        \n",
        "        val_losses.append(loss.item())\n",
        "        \n",
        "      val_loss_mean = np.mean(val_losses)\n",
        "      total_val_losses.append(val_loss_mean)\n",
        "\n",
        "      print(f\"Epoch {epoch} Training loss: {train_loss_mean} Validation loss: {val_loss_mean}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(total_train_losses)\n",
        "plt.plot(total_val_losses)\n",
        "plt.title(\"CNN: Training & Val Loss VS Number of iteration\")\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-RViwrvEK8jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kLEPhWFA5Pn"
      },
      "source": [
        "Predictions on testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6fSzOY0OtKg"
      },
      "outputs": [],
      "source": [
        "test_files = os.listdir(test_images)\n",
        "test_files = [x.split('.')[0] for x in test_files if x[0].isnumeric()]\n",
        "test_files.sort()\n",
        "test_files = np.array(test_files)\n",
        "\n",
        "#dim = 512\n",
        "#img_list = []\n",
        "\n",
        "#for im_file in test_files:\n",
        "#    img = cv2.imread(f'{test_images}/{im_file}.tif')\n",
        "#    img = cv2.resize(img,(dim,dim))\n",
        "#    img = img / 255.0\n",
        "\n",
        "#    img_list.append(img)\n",
        "\n",
        "#img_list = np.stack(img_list)\n",
        "#print(img_list.shape)\n",
        "\n",
        "#means = np.mean(img_list,axis=(0,1,2))\n",
        "#stdevs = np.std(img_list,axis=(0,1,2))\n",
        "\n",
        "#print(means,stdevs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ad1jR3kfShVt"
      },
      "outputs": [],
      "source": [
        "means = [0.3720225,  0.44640904, 0.42115532]\n",
        "stdevs = [0.21046157, 0.18250105, 0.20091524]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trVoIEUFOpev"
      },
      "outputs": [],
      "source": [
        "class testDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, img_path, X, mean, std, aug=None):\n",
        "        self.img_path = img_path\n",
        "        self.X = X\n",
        "        self.aug = aug\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img = cv2.imread(f'{self.img_path}/{self.X[idx]}.tif')\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  \n",
        "        if self.aug is not None:\n",
        "            aug = self.aug(image=img)\n",
        "            img = Image.fromarray(aug['image'])\n",
        "        \n",
        "        if self.aug is None:\n",
        "            img = Image.fromarray(img)\n",
        "        \n",
        "        transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(self.mean, self.std)])\n",
        "        img = transform(img)\n",
        "            \n",
        "        return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIPXb0urTQtX"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_set = testDataset(test_images, test_files, means, stdevs, transform_val)\n",
        "\n",
        "#dataloader\n",
        "batch_size= 1\n",
        "\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, num_workers = 1, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "UCRfs8HHA5Po"
      },
      "outputs": [],
      "source": [
        "from itertools import islice\n",
        "#Predict the test set maps\n",
        "model.eval()\n",
        "test_predictions = []\n",
        "for image in test_loader:\n",
        "    with torch.no_grad():\n",
        "        image = image.to(device)\n",
        "        prediction = model(image)\n",
        "        test_predictions.append(np.uint8(prediction.argmax(1).cpu().numpy()[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OijQBLintIF3"
      },
      "outputs": [],
      "source": [
        "#Saving images to output path \n",
        "test_dir = r'/content/drive/MyDrive/DSBA/Hurricane_Harvey/double_conv/pred/'\n",
        "test_img_names = list(test_files)\n",
        "d = dict(zip(test_img_names,test_predictions))\n",
        "for name, pred in d.items():\n",
        "    im = Image.fromarray(pred)\n",
        "    im.save(test_dir+name+'.png')\n",
        "    print(\"Image saved: \", test_dir + name + '.png')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store the image sizes\n",
        "\n",
        "images = os.listdir(test_images)\n",
        "images = [x for x in images if x[0].isnumeric()]\n",
        "\n",
        "def get_size(images):\n",
        "  image_size = {}\n",
        "  for image in images:\n",
        "    image_id = image.split('.')[0]\n",
        "    \n",
        "    with PIL.Image.open(f'{test_images}/{image}') as im:\n",
        "      width, height = im.size\n",
        "      image_size[image_id] = (width, height)\n",
        "\n",
        "  return image_size\n",
        "\n",
        "image_size = get_size(images)"
      ],
      "metadata": {
        "id": "nSJm6p6IyCXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCGOzIhVaAWI"
      },
      "outputs": [],
      "source": [
        "image_paths = r'/content/drive/MyDrive/DSBA/Hurricane_Harvey/double_conv/pred'\n",
        "reshape_dir = r'/content/drive/MyDrive/DSBA/Hurricane_Harvey/double_conv/pred_resize'\n",
        "\n",
        "images = os.listdir(image_paths)\n",
        "images = [x for x in images if x[0].isnumeric()]\n",
        "\n",
        "# the target size is image_size\n",
        "for file_path in images:\n",
        "  image_id = file_path.split('.')[0]\n",
        "  width,height = image_size[image_id]\n",
        "\n",
        "  im = cv2.imread(f'{image_paths}/{file_path}', cv2.IMREAD_GRAYSCALE)\n",
        "  im = cv2.resize(im,(width, height),interpolation = cv2.INTER_NEAREST)\n",
        "  cv2.imwrite(f'{reshape_dir}/{file_path}',im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LlQzdCDdTw7"
      },
      "outputs": [],
      "source": [
        "#palette = torch.tensor([2 ** 25 - 1, 2 ** 15 - 1, 2 ** 21 - 1])\n",
        "#colors = torch.as_tensor([i for i in range(27)])[:, None] * palette\n",
        "#colors = (colors % 255).numpy().astype(\"uint8\")\n",
        "\n",
        "#reshape_dir = r'/content/drive/MyDrive/DSBA/Hurricane_Harvey/rasters/double_conv/pred_resize'\n",
        "#images = os.listdir(reshape_dir)\n",
        "#images = [x for x in images if x[0].isnumeric()]\n",
        "\n",
        "#for img in images:\n",
        "#  image = cv2.imread(f'{reshape_dir}/{img}', cv2.IMREAD_GRAYSCALE)\n",
        "#  plt.figure()\n",
        "#  plt.imshow(image)\n",
        "#  plt.title(img)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN9Q8XccA5Pq"
      },
      "source": [
        "Preparing data for submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9_j7hUZOBcE"
      },
      "outputs": [],
      "source": [
        "# zip file\n",
        "import tarfile  \n",
        "\n",
        "tar = tarfile.open(\"submission.zip\", \"w\")  \n",
        "for root, dir, files in os.walk(reshape_dir):\n",
        "  for file in files:\n",
        "    fullpath = os.path.join(root, file)\n",
        "    tar.add(fullpath, arcname=file)\n",
        "tar.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Omlq4cx2Vanf"
      },
      "outputs": [],
      "source": [
        "# check if reshape is successful\n",
        "\n",
        "f = os.listdir(reshape_dir)\n",
        "\n",
        "image_size = {}\n",
        "for image in f:\n",
        "  image_id = image.split('.')[0]\n",
        "  with PIL.Image.open(f'{reshape_dir}/{image}') as im:\n",
        "    width, height = im.size\n",
        "    image_size[image_id] = (width, height)\n",
        "print(image_size)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}